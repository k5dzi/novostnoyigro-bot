import feedparser
import aiohttp
import asyncio
from datetime import datetime, timedelta

RSS_SOURCES = [
    {
        'name': 'DTF –ò–≥—Ä—ã',
        'url': 'https://dtf.ru/r/games/go',  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è —Å—Å—ã–ª–∫–∞
        'category': 'games'
    },
    {
        'name': 'StopGame',
        'url': 'https://stopgame.ru/rss/news.xml',
        'category': 'news'
    },
    {
        'name': 'Igromania',
        'url': 'https://www.igromania.ru/rss/news.xml',
        'category': 'news'
    },
    {
        'name': 'Kanobu',
        'url': 'https://kanobu.ru/rss/news.xml',
        'category': 'news'
    },
    {
        'name': 'Cybersport.ru',
        'url': 'https://www.cybersport.ru/rss',
        'category': 'esports'
    }
]


async def parse_rss_feeds():
    """–ü–∞—Ä—Å–∏–º RSS-–ª–µ–Ω—Ç—ã"""
    news = []

    for source in RSS_SOURCES:
        try:
            print(f"üì° –ü–∞—Ä—Å–∏–º RSS: {source['name']}")
            feed = feedparser.parse(source['url'])

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –ø–∞—Ä—Å–∏–Ω–≥–∞
            if feed.bozo == 1:  # –µ—Å—Ç—å –æ—à–∏–±–∫–∏ –≤ RSS
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ RSS {source['name']}: {feed.bozo_exception}")
                continue

            for entry in feed.entries[:15]:  # –ë–µ—Ä–µ–º 15 –ø–æ—Å–ª–µ–¥–Ω–∏—Ö
                # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞—Ç—ã
                published_time = None
                if hasattr(entry, 'published_parsed') and entry.published_parsed:
                    try:
                        published_time = datetime(*entry.published_parsed[:6])
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–≤–µ–∂–µ—Å—Ç—å (–Ω–µ —Å—Ç–∞—Ä—à–µ 48 —á–∞—Å–æ–≤)
                        if datetime.now() - published_time > timedelta(hours=48):
                            continue
                    except (TypeError, ValueError):
                        pass

                news.append({
                    'title': entry.title,
                    'link': entry.link,
                    'description': getattr(entry, 'summary', ''),
                    'source': source['name'],
                    'category': source['category'],
                    'published': published_time,
                    'image_url': find_image_in_entry(entry)
                })

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {source['name']}: {e}")

    print(f"‚úÖ RSS –Ω–æ–≤–æ—Å—Ç–µ–π —Å–æ–±—Ä–∞–Ω–æ: {len(news)}")
    return news


def find_image_in_entry(entry):
    """–ò—â–µ–º –∫–∞—Ä—Ç–∏–Ω–∫—É –≤ RSS-–∑–∞–ø–∏—Å–∏"""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–µ–¥–∏–∞-–∫–æ–Ω—Ç–µ–Ω—Ç
        if hasattr(entry, 'media_content'):
            for media in entry.media_content:
                if media.get('type', '').startswith('image'):
                    return media['url']

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Å—ã–ª–∫–∏
        if hasattr(entry, 'links'):
            for link in entry.links:
                if hasattr(link, 'type') and link.type and 'image' in link.type:
                    return link.href

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç
        if hasattr(entry, 'content'):
            for content in entry.content:
                if 'image' in getattr(content, 'type', ''):
                    return getattr(content, 'value', '')

    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –∫–∞—Ä—Ç–∏–Ω–∫–∏: {e}")

    return None
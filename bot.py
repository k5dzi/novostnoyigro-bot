import os
import asyncio
import logging
import schedule
import time
import sqlite3
import hashlib
import random
from datetime import datetime, timedelta
from telegram import Bot
from config import BOT_TOKEN, CHANNEL_ID, DB_CONFIG
import feedparser
import requests
from bs4 import BeautifulSoup
from typing import List, Dict, Optional

# ==================== –ù–ê–°–¢–†–û–ô–ö–ê –õ–û–ì–ì–ò–†–û–í–ê–ù–ò–Ø ====================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('news_bot.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


# ==================== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ====================
class Config:
    BOT_TOKEN = BOT_TOKEN
    CHANNEL_ID = CHANNEL_ID

    # –ë–∞–∑–æ–≤—ã–µ —á–∞—Å—ã (—Å 7:00 –¥–æ 00:00)
    BASE_HOURS = list(range(7, 24)) + [0]  # [7, 8, 9, ..., 23, 0]
    MAX_MESSAGE_LENGTH = 1024
    RSS_LIMIT = 15
    HTML_LIMIT = 10

    @staticmethod
    def generate_random_schedule():
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–ª—É—á–∞–π–Ω–æ–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ –¥–µ–Ω—å"""
        schedule_times = []
        for hour in Config.BASE_HOURS:
            # –°–ª—É—á–∞–π–Ω—ã–µ –º–∏–Ω—É—Ç—ã –æ—Ç 0 –¥–æ 55
            minutes = random.randint(0, 55)
            time_str = f"{hour:02d}:{minutes:02d}"
            schedule_times.append(time_str)
        return schedule_times


# ==================== –ú–û–î–ï–õ–ò –î–ê–ù–ù–´–• ====================
class NewsArticle:
    def __init__(self, title: str, link: str, source: str, category: str = "general",
                 description: str = "", image_url: str = None):
        self.title = title
        self.link = link
        self.source = source
        self.category = category
        self.description = description
        self.image_url = image_url
        self.id = self.generate_id()

    def generate_id(self) -> str:
        content = f"{self.title}{self.link}".encode('utf-8')
        return hashlib.md5(content).hexdigest()

    def to_dict(self) -> Dict:
        return {
            'title': self.title,
            'link': self.link,
            'source': self.source,
            'category': self.category,
            'description': self.description,
            'image_url': self.image_url,
            'id': self.id
        }


# ==================== –ë–ê–ó–ê –î–ê–ù–ù–´–• ====================
class DatabaseManager:
    def __init__(self):
        self.connection = None

    def get_connection(self):
        if not self.connection:
            try:
                self.connection = sqlite3.connect(DB_CONFIG['database'], check_same_thread=False)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î: {e}")
                raise
        return self.connection

    def init_database(self):
        conn = self.get_connection()
        cursor = conn.cursor()

        try:
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS posted_news (
                    id TEXT PRIMARY KEY,
                    title TEXT NOT NULL,
                    link TEXT NOT NULL,
                    posted_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    source TEXT,
                    category TEXT
                )
            ''')

            cursor.execute('''
                CREATE TABLE IF NOT EXISTS news_reserve (
                    id TEXT PRIMARY KEY,
                    title TEXT NOT NULL,
                    link TEXT NOT NULL,
                    image_url TEXT,
                    source TEXT,
                    description TEXT,
                    category TEXT,
                    added_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    used BOOLEAN DEFAULT FALSE
                )
            ''')

            conn.commit()
            logger.info("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö SQLite –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ë–î: {e}")
            conn.rollback()
        finally:
            cursor.close()

    def is_news_posted(self, news_id: str) -> bool:
        conn = self.get_connection()
        cursor = conn.cursor()

        try:
            cursor.execute('SELECT id FROM posted_news WHERE id = ?', (news_id,))
            return cursor.fetchone() is not None
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–æ–≤–æ—Å—Ç–∏: {e}")
            return False
        finally:
            cursor.close()

    def mark_news_as_posted(self, article: NewsArticle):
        conn = self.get_connection()
        cursor = conn.cursor()

        try:
            cursor.execute(
                'INSERT INTO posted_news (id, title, link, source, category) VALUES (?, ?, ?, ?, ?)',
                (article.id, article.title, article.link, article.source, article.category)
            )
            conn.commit()
            logger.info(f"‚úÖ –ù–æ–≤–æ—Å—Ç—å –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–µ: {article.title[:50]}...")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–∏: {e}")
            conn.rollback()
        finally:
            cursor.close()

    def add_to_reserve(self, articles: List[NewsArticle]):
        conn = self.get_connection()
        cursor = conn.cursor()
        added_count = 0

        try:
            for article in articles:
                if not self.is_news_posted(article.id):
                    cursor.execute('SELECT id FROM news_reserve WHERE id = ?', (article.id,))
                    if not cursor.fetchone():
                        cursor.execute(
                            '''INSERT INTO news_reserve 
                            (id, title, link, image_url, source, description, category) 
                            VALUES (?, ?, ?, ?, ?, ?, ?)''',
                            (article.id, article.title, article.link, article.image_url,
                             article.source, article.description, article.category)
                        )
                        added_count += 1

            conn.commit()
            logger.info(f"üíæ –í —Ä–µ–∑–µ—Ä–≤ –¥–æ–±–∞–≤–ª–µ–Ω–æ –Ω–æ–≤–æ—Å—Ç–µ–π: {added_count}")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ —Ä–µ–∑–µ—Ä–≤: {e}")
            conn.rollback()
        finally:
            cursor.close()

    def get_reserve_news(self, count: int = 1) -> List[NewsArticle]:
        conn = self.get_connection()
        cursor = conn.cursor()
        articles = []

        try:
            cursor.execute('''
                SELECT id, title, link, image_url, source, description, category 
                FROM news_reserve 
                WHERE used = FALSE 
                ORDER BY added_at 
                LIMIT ?
            ''', (count,))

            for row in cursor.fetchall():
                news_id, title, link, image_url, source, description, category = row
                article = NewsArticle(title, link, source, category, description, image_url)
                article.id = news_id
                articles.append(article)

                cursor.execute('UPDATE news_reserve SET used = TRUE WHERE id = ?', (news_id,))

            conn.commit()
            logger.info(f"üì• –ò–∑ —Ä–µ–∑–µ—Ä–≤–∞ –ø–æ–ª—É—á–µ–Ω–æ –Ω–æ–≤–æ—Å—Ç–µ–π: {len(articles)}")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–∑ —Ä–µ–∑–µ—Ä–≤–∞: {e}")
            conn.rollback()
        finally:
            cursor.close()

        return articles

    def get_reserve_count(self) -> int:
        conn = self.get_connection()
        cursor = conn.cursor()

        try:
            cursor.execute('SELECT COUNT(*) FROM news_reserve WHERE used = FALSE')
            return cursor.fetchone()[0]
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥—Å—á–µ—Ç–∞ —Ä–µ–∑–µ—Ä–≤–∞: {e}")
            return 0
        finally:
            cursor.close()


# ==================== –ü–ê–†–°–ï–†–´ –ù–û–í–û–°–¢–ï–ô ====================
class NewsParser:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })


class RSSParser(NewsParser):
    RSS_SOURCES = [
        {'name': 'DTF –ò–≥—Ä—ã', 'url': 'https://dtf.ru/r/games/go', 'category': 'games'},
        {'name': 'StopGame', 'url': 'https://stopgame.ru/rss/news.xml', 'category': 'news'},
        {'name': 'Igromania', 'url': 'https://www.igromania.ru/rss/news.xml', 'category': 'news'},
        {'name': 'Kanobu', 'url': 'https://kanobu.ru/rss/news.xml', 'category': 'news'},
        {'name': 'Cybersport.ru', 'url': 'https://www.cybersport.ru/rss', 'category': 'esports'}
    ]

    async def parse_feeds(self) -> List[NewsArticle]:
        logger.info("üì° –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞ RSS-–ª–µ–Ω—Ç")
        all_articles = []

        for source in self.RSS_SOURCES:
            try:
                articles = await self.parse_single_feed(source)
                all_articles.extend(articles)
                logger.info(f"‚úÖ {source['name']}: {len(articles)} –Ω–æ–≤–æ—Å—Ç–µ–π")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {source['name']}: {e}")

        logger.info(f"üì° –í—Å–µ–≥–æ RSS-–Ω–æ–≤–æ—Å—Ç–µ–π: {len(all_articles)}")
        return all_articles

    async def parse_single_feed(self, source: Dict) -> List[NewsArticle]:
        articles = []

        loop = asyncio.get_event_loop()
        feed = await loop.run_in_executor(None, feedparser.parse, source['url'])

        for entry in feed.entries[:Config.RSS_LIMIT]:
            if hasattr(entry, 'published_parsed'):
                published_time = datetime(*entry.published_parsed[:6])
                if datetime.now() - published_time > timedelta(hours=48):
                    continue

            article = NewsArticle(
                title=entry.title,
                link=entry.link,
                source=source['name'],
                category=source['category'],
                description=getattr(entry, 'summary', ''),
                image_url=self.find_image_in_entry(entry)
            )
            articles.append(article)

        return articles

    def find_image_in_entry(self, entry) -> Optional[str]:
        if hasattr(entry, 'links'):
            for link in entry.links:
                if hasattr(link, 'type') and link.type and 'image' in link.type:
                    return link.href

        if hasattr(entry, 'media_content'):
            for media in entry.media_content:
                if media.get('type', '').startswith('image'):
                    return media['url']

        return None


class HTMLParser(NewsParser):
    def parse_dtf(self) -> List[NewsArticle]:
        logger.info("üåê –ü–∞—Ä—Å–∏–Ω–≥ DTF HTML")
        articles = []

        try:
            url = "https://dtf.ru/games"
            response = self.session.get(url, timeout=10)
            soup = BeautifulSoup(response.text, 'html.parser')

            for article_tag in soup.find_all('article')[:Config.HTML_LIMIT]:
                title_tag = article_tag.find('h2', class_='content-title')
                if not title_tag:
                    continue

                link_tag = title_tag.find('a')
                if not link_tag:
                    continue

                title = link_tag.text.strip()
                link = "https://dtf.ru" + link_tag['href']

                description_tag = article_tag.find('div', class_='content-description')
                description = description_tag.text.strip() if description_tag else ""

                image_url = None
                img_tag = article_tag.find('img')
                if img_tag and img_tag.get('src'):
                    image_url = img_tag['src']
                    if image_url.startswith('//'):
                        image_url = 'https:' + image_url

                article = NewsArticle(
                    title=title,
                    link=link,
                    source='DTF',
                    category='games',
                    description=description,
                    image_url=image_url
                )
                articles.append(article)

            logger.info(f"‚úÖ DTF HTML: {len(articles)} –Ω–æ–≤–æ—Å—Ç–µ–π")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ DTF: {e}")

        return articles


# ==================== –û–ë–†–ê–ë–û–¢–ß–ò–ö –ö–û–ù–¢–ï–ù–¢–ê ====================
class ContentEnhancer:
    CATEGORY_EMOJIS = {
        'games': 'üéÆ',
        'news': 'üì∞',
        'esports': 'üèÜ',
        'general': 'üì¢'
    }

    CATEGORY_DESCRIPTIONS = {
        'games': {
            'intro': 'üéØ **–ù–æ–≤–æ—Å—Ç—å –∏–∑ –º–∏—Ä–∞ –≤–∏–¥–µ–æ–∏–≥—Ä**'
        },
        'esports': {
            'intro': 'üèÜ **–ù–æ–≤–æ—Å—Ç–∏ –∫–∏–±–µ—Ä—Å–ø–æ—Ä—Ç–∞**'
        },
        'news': {
            'intro': 'üì¢ **–ê–∫—Ç—É–∞–ª—å–Ω–∞—è –Ω–æ–≤–æ—Å—Ç—å**'
        }
    }

    def enhance(self, article: NewsArticle) -> Dict:
        category = article.category
        emoji = self.CATEGORY_EMOJIS.get(category, 'üì¢')
        desc_config = self.CATEGORY_DESCRIPTIONS.get(category, self.CATEGORY_DESCRIPTIONS['news'])

        description = self._format_description(article, desc_config)
        link_text = self._format_link(article.link)

        return {
            'title': article.title,
            'description': description,
            'link_text': link_text,
            'image_url': article.image_url,
            'has_image': article.image_url is not None,
            'category': category,
            'emoji': emoji
        }

    def _format_description(self, article: NewsArticle, config: Dict) -> str:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–ª–∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–º–Ω–æ–µ
        if article.description and len(article.description.strip()) > 50:
            description = self._clean_description(article.description)
        else:
            description = self._generate_smart_description(article.title)

        return f"""{config['intro']}

üìä {description}

üí¨ *–û–±—Å—É–∂–¥–µ–Ω–∏–µ –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤—É–µ—Ç—Å—è!*

üåê **–ò—Å—Ç–æ—á–Ω–∏–∫:** {article.source}"""

    def _clean_description(self, text: str) -> str:
        """–û—á–∏—â–∞–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ –æ—Ç HTML-—Ç–µ–≥–æ–≤"""
        import re
        text = re.sub(r'<[^>]+>', '', text)
        text = re.sub(r'\s+', ' ', text)
        if len(text) > 400:
            text = text[:400] + '...'
        return text.strip()

    def _generate_smart_description(self, title: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–º–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
        title_lower = title.lower()

        if any(word in title_lower for word in ['–∞–Ω–æ–Ω—Å', '–ø–æ–∫–∞–∑–∞–ª', '–ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª', '–∞–Ω–æ–Ω—Å–∏—Ä–æ–≤–∞–ª']):
            return "–†–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∏ –ø–æ–¥–µ–ª–∏–ª–∏—Å—å –Ω–æ–≤—ã–º–∏ –¥–µ—Ç–∞–ª—è–º–∏ –ø—Ä–æ–µ–∫—Ç–∞. –°–æ–æ–±—â–µ—Å—Ç–≤–æ –∞–∫—Ç–∏–≤–Ω–æ –æ–±—Å—É–∂–¥–∞–µ—Ç —Å–≤–µ–∂—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é."
        elif any(word in title_lower for word in ['–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ', '–ø–∞—Ç—á', '–≤–µ—Ä—Å–∏—è']):
            return "–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–Ω–µ—Å–ª–æ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –∏–≥—Ä–æ–≤–æ–π –ø—Ä–æ—Ü–µ—Å—Å –∏ –±–∞–ª–∞–Ω—Å."
        elif any(word in title_lower for word in ['—Ç—Ä–µ–π–ª–µ—Ä', '–≤–∏–¥–µ–æ', '–≥–µ–π–º–ø–ª–µ–π']):
            return "–ù–æ–≤—ã–π –≤–∏–¥–µ–æ–º–∞—Ç–µ—Ä–∏–∞–ª –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –∫–ª—é—á–µ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –∏ –≥–µ–π–º–ø–ª–µ–π."
        elif any(word in title_lower for word in ['—Å–∫–∏–¥–∫–∞', '—Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∞', 'sale']):
            return "–û—Ç–ª–∏—á–Ω–∞—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–æ–±—Ä–µ—Å—Ç–∏ –∏–≥—Ä—É –ø–æ –≤—ã–≥–æ–¥–Ω–æ–π —Ü–µ–Ω–µ."
        else:
            return "–°–≤–µ–∂–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–æ–±—ã—Ç–∏—è—Ö –≤ –∏–≥—Ä–æ–≤–æ–π –∏–Ω–¥—É—Å—Ç—Ä–∏–∏."

    def _format_link(self, link: str) -> str:
        if 'steam' in link.lower():
            return f"[üéÆ Steam]({link})"
        elif 'dtf' in link.lower():
            return f"[üìù DTF]({link})"
        else:
            return f"[üåê –ß–∏—Ç–∞—Ç—å –¥–∞–ª–µ–µ]({link})"


# ==================== –¢–ï–õ–ï–ì–†–ê–ú –ë–û–¢ ====================
class TelegramBot:
    def __init__(self):
        self.bot = Bot(token=Config.BOT_TOKEN)
        self.enhancer = ContentEnhancer()

    async def send_news(self, article: NewsArticle) -> bool:
        try:
            enhanced = self.enhancer.enhance(article)
            message = self._format_message(enhanced)

            if enhanced['has_image']:
                return await self._send_with_photo(message, enhanced)
            else:
                return await self._send_text_message(message)

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –Ω–æ–≤–æ—Å—Ç–∏: {e}")
            return False

    def _format_message(self, enhanced: Dict) -> str:
        message = f"""{enhanced['emoji']} **{enhanced['title']}**

{enhanced['description']}

üîó {enhanced['link_text']}"""

        if len(message) > Config.MAX_MESSAGE_LENGTH:
            message = message[:Config.MAX_MESSAGE_LENGTH - 3] + "..."

        return message

    async def _send_with_photo(self, message: str, enhanced: Dict) -> bool:
        try:
            await self.bot.send_photo(
                chat_id=Config.CHANNEL_ID,
                photo=enhanced['image_url'],
                caption=message,
                parse_mode='Markdown'
            )
            return True
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å —Ñ–æ—Ç–æ: {e}")
            return await self._send_text_message(message)

    async def _send_text_message(self, message: str) -> bool:
        try:
            await self.bot.send_message(
                chat_id=Config.CHANNEL_ID,
                text=message,
                parse_mode='Markdown',
                disable_web_page_preview=True
            )
            return True
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
            return False


# ==================== –û–°–ù–û–í–ù–û–ô –ö–õ–ê–°–° –ë–û–¢–ê ====================
class NewsBot:
    def __init__(self):
        self.db = DatabaseManager()
        self.telegram = TelegramBot()
        self.rss_parser = RSSParser()
        self.html_parser = HTMLParser()
        self.daily_schedule = []

    async def collect_news(self) -> List[NewsArticle]:
        logger.info("üï∏Ô∏è –°–±–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π —Å–æ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤")
        all_articles = []

        rss_articles = await self.rss_parser.parse_feeds()
        all_articles.extend(rss_articles)

        if len(all_articles) < 3:
            html_articles = self.html_parser.parse_dtf()
            all_articles.extend(html_articles)

        unique_articles = self._remove_duplicates(all_articles)
        logger.info(f"‚úÖ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π: {len(unique_articles)}")

        return unique_articles

    def _remove_duplicates(self, articles: List[NewsArticle]) -> List[NewsArticle]:
        seen_titles = set()
        unique_articles = []

        for article in articles:
            if article.title not in seen_titles:
                seen_titles.add(article.title)
                unique_articles.append(article)

        return unique_articles

    async def publish_news(self):
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –Ω–æ–≤–æ—Å—Ç–µ–π")

        try:


            fresh_articles = await self.collect_news()
            # ... –æ—Å—Ç–∞–ª—å–Ω–æ–π –∫–æ–¥

            if not fresh_articles:
                logger.warning("üì≠ –ù–æ–≤–æ—Å—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∑–µ—Ä–≤")
                fresh_articles = self._get_fallback_news()

            if len(fresh_articles) > 1:
                reserve_articles = fresh_articles[1:]
                self.db.add_to_reserve(reserve_articles)

            article_to_publish = await self._select_article_to_publish(fresh_articles)

            if not article_to_publish:
                logger.warning("üì≠ –ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏")
                return

            success = await self.telegram.send_news(article_to_publish)

            if success:
                self.db.mark_news_as_posted(article_to_publish)
                logger.info(f"‚úÖ –ù–æ–≤–æ—Å—Ç—å –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–∞: {article_to_publish.title[:50]}...")

                reserve_count = self.db.get_reserve_count()
                logger.info(f"üíæ –ù–æ–≤–æ—Å—Ç–µ–π –≤ —Ä–µ–∑–µ—Ä–≤–µ: {reserve_count}")
            else:
                logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å –Ω–æ–≤–æ—Å—Ç—å")

        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏: {e}")

    async def _select_article_to_publish(self, fresh_articles: List[NewsArticle]) -> Optional[NewsArticle]:
        if fresh_articles:
            for article in fresh_articles:
                if not self.db.is_news_posted(article.id):
                    return article

        reserve_articles = self.db.get_reserve_news(1)
        if reserve_articles:
            return reserve_articles[0]

        return None

    def _get_fallback_news(self) -> List[NewsArticle]:
        return [NewsArticle(
            title='–ò–≥—Ä–æ–≤–∞—è –∏–Ω–¥—É—Å—Ç—Ä–∏—è: –ø–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –∏ —Ç—Ä–µ–Ω–¥—ã',
            link='https://store.steampowered.com',
            source='Steam',
            category='games',
            description='–ê–∫—Ç—É–∞–ª—å–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è –∏–∑ –º–∏—Ä–∞ –≤–∏–¥–µ–æ–∏–≥—Ä'
        )]

    def setup_schedule(self):
        """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç —Å–ª—É—á–∞–π–Ω–æ–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ –¥–µ–Ω—å"""
        self.daily_schedule = Config.generate_random_schedule()

        # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä–æ–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ
        schedule.clear()

        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤–æ–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ
        for time_str in self.daily_schedule:
            schedule.every().day.at(time_str).do(lambda: asyncio.run(self.publish_news()))

        logger.info(f"‚è∞ –†–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ –¥–µ–Ω—å –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ:")
        for i, time_str in enumerate(self.daily_schedule, 1):
            logger.info(f"   {i:2d}. {time_str}")

    def run(self):
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ —É–º–Ω–æ–≥–æ –±–æ—Ç–∞ –Ω–æ–≤–æ—Å—Ç–µ–π...")

        self.db.init_database()
        self.setup_schedule()

        # –ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫
        logger.info("üéØ –ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏...")
        asyncio.run(self.publish_news())

        logger.info("\n‚è∞ –ë–æ—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç –ø–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é...")
        logger.info("üìÖ –†–∞–±–æ—á–µ–µ –≤—Ä–µ–º—è: 7:00 - 00:00 (18 –ø—É–±–ª–∏–∫–∞—Ü–∏–π –≤ –¥–µ–Ω—å)")
        logger.info("üé≤ –°–ª—É—á–∞–π–Ω–æ–µ –≤—Ä–µ–º—è –≤ —Ç–µ—á–µ–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ —á–∞—Å–∞")
        logger.info("üíæ –°–∏—Å—Ç–µ–º–∞ —Ä–µ–∑–µ—Ä–≤–∞ –∞–∫—Ç–∏–≤–Ω–∞")
        logger.info("üì° –ò—Å—Ç–æ—á–Ω–∏–∫–∏: RSS + HTML –ø–∞—Ä—Å–µ—Ä—ã")
        logger.info("‚è∏Ô∏è –î–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏: Ctrl+C")

        # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª
        try:
            while True:
                schedule.run_pending()
                time.sleep(30)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–µ 30 —Å–µ–∫—É–Ω–¥

                # –ö–∞–∂–¥—ã–π –¥–µ–Ω—å –≤ 6:00 –æ–±–Ω–æ–≤–ª—è–µ–º —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ
                if datetime.now().hour == 6 and datetime.now().minute == 0:
                    logger.info("üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è –Ω–∞ –Ω–æ–≤—ã–π –¥–µ–Ω—å...")
                    self.setup_schedule()
                    time.sleep(60)  # –ñ–¥–µ–º –º–∏–Ω—É—Ç—É —á—Ç–æ–±—ã –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–æ –ø–æ–≤—Ç–æ—Ä–Ω–æ

        except KeyboardInterrupt:
            logger.info("\nüõë –ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")


# ==================== –ó–ê–ü–£–°–ö ====================
if __name__ == "__main__":
    bot = NewsBot()
    bot.run()